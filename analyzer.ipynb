{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd9ac20",
      "metadata": {
        "id": "cdd9ac20"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import kendalltau\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "import os, shutil, gc\n",
        "import torch\n",
        "\n",
        "REF_MODELS = [\n",
        "    \"Yi-1.5-9B-Chat\",\n",
        "    \"Meta-Llama-3.1-8B-Instruct\",\n",
        "    \"Phi-3-medium-128k-instruct\",\n",
        "    \"Mistral-7B-Instruct-v0.3\",\n",
        "    \"Qwen2.5-0.5B-Instruct\",\n",
        "    \"Qwen2.5-1.5B-Instruct\",\n",
        "    \"Qwen3-4B-Instruct-2507\"\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b54a94bc",
      "metadata": {
        "id": "b54a94bc"
      },
      "source": [
        "# Renaming Filenames for Compatibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150c9979",
      "metadata": {
        "id": "150c9979"
      },
      "outputs": [],
      "source": [
        "# renaming Aymen's files for better f-string-types.\n",
        "fnames = sorted([f for f in os.listdir(\"raw_results/aymen\") if \".csv\" in f])\n",
        "for fname in fnames:\n",
        "\n",
        "    # get the new filename\n",
        "    new_fname = fname.replace(\"training_logs_\", \"\").replace(\"arwc_normalized\", \"Original\")\\\n",
        "    .replace(\"offline_1\", \"VDW\").replace(\"offline_2\", \"VAW\")\\\n",
        "    .replace(\"online_1\", \"SWCW\").replace(\"online_2\", \"TSW\")\n",
        "\n",
        "    # save these files\n",
        "    os.rename(f\"raw_results/aymen/{fname}\", f\"raw_results/aymen/{new_fname}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6daa1739",
      "metadata": {
        "id": "6daa1739"
      },
      "outputs": [],
      "source": [
        "# renaming Skyler's files for better f-string-types\n",
        "fnames = sorted([f for f in os.listdir(\"raw_results/skyler\") if \".csv\" in f])\n",
        "\n",
        "for fname in fnames:\n",
        "\n",
        "    # get our new filename\n",
        "    new_fname = fname.replace(\"PKU-SafeRLHF-30K-standard\", \"SafeRLHF\").replace(\"ultrafeedback_binarized\", \"UltraFeedback\")\\\n",
        "    .replace(\"Offline-1-One-Hot\", \"SWCW-OH\").replace(\"Thompson-DPO\", \"TSW\").replace(\"baseline-DPO\", \"DPO\")\\\n",
        "    .replace(\"01-ai_Yi-1.5-9B-Chat\", \"Yi-1.5-9B\").replace(\"Qwen_Qwen2.5-0.5B-Instruct\", \"Qwen2.5-0.5B\")\\\n",
        "    .replace(\"Qwen_Qwen2.5-1.5B-Instruct\", \"Qwen2.5-1.5B\")\\\n",
        "    .replace(\"Qwen_Qwen3-4B-Instruct-2507\", \"Qwen3-4B\")\\\n",
        "    .replace(\"meta-llama_Meta-Llama-3.1-8B-Instruct\", \"Llama-3.1-8B\")\\\n",
        "    .replace(\"microsoft_Phi-3-medium-128k-instruct\", \"Phi-3-Medium-128k\")\\\n",
        "    .replace(\"mistralai_Mistral-7B-Instruct-v0.3\", \"Mistral-7B\")\n",
        "\n",
        "    # save these files\n",
        "    os.rename(f\"raw_results/skyler/{fname}\", f\"raw_results/skyler/{new_fname}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d514e8d7",
      "metadata": {
        "id": "d514e8d7"
      },
      "source": [
        "# Summarizing Relevant Metrics Per Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed3b7f71",
      "metadata": {
        "id": "ed3b7f71"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "List of Methods:\n",
        "DPO - 7x reference models (FINISHED)\n",
        "Original - MRPO/MDPO: 2x.\n",
        "VDW - MRPO/MDPO: 2x (\"Offline 1\") (FINISHED)\n",
        "VAW - MRPO/MDPO: 2x (\"Offline 2\") (FINISHED)\n",
        "SWCW - MRPO/MDPO: 2x (\"Online 1\") (FINISHED)\n",
        "SWCW-OH - MRPO/MDPO: 2x (\"Online 1 (0-1)\") (FINISHED)\n",
        "TSW - 1x (\"Online 2\") (FINISHED)\n",
        "'''\n",
        "# create summary logs for DPO: final test acc, Delta (batch-acc-pre, post) (<0, =0, >0)\n",
        "dpo_summary = pd.DataFrame(\n",
        "    data=None, columns=[\n",
        "        \"method\", \"dataset\", \"reference\", \"seed\", \"final_test_acc\",\n",
        "        \"prop_delta_neg\", \"prop_delta_zero\", \"prop_delta_pos\"])\n",
        "\n",
        "# fill out these logs for DPO.\n",
        "dpo_fnames = sorted([f for f in os.listdir(\"raw_results/skyler\") if \"DPO\" in f])\n",
        "for fname in dpo_fnames:\n",
        "\n",
        "    # record our settings\n",
        "    method = \"DPO\"\n",
        "    dataset = fname.split(\"_\")[1].split(\"=\")[1]\n",
        "    reference = fname.split(\"_\")[2].split(\"=\")[1]\n",
        "    seed = int(fname.split(\"_\")[3].split(\"=\")[1].split(\".csv\")[0])\n",
        "\n",
        "    # load in our dataframe\n",
        "    df = pd.read_csv(f\"raw_results/skyler/{fname}\")\n",
        "    final_test_acc = df.test_acc.values[-1]\n",
        "\n",
        "    # compute our delta statistics\n",
        "    deltas = (df.batch_acc_post - df.batch_acc_pre)\n",
        "    prop_delta_neg = (deltas < 0).mean()\n",
        "    prop_delta_zero = (deltas == 0).mean()\n",
        "    prop_delta_pos = (deltas > 0).mean()\n",
        "\n",
        "    # assemble row + add to our dataframe\n",
        "    row = [method, dataset, reference, seed, final_test_acc,\n",
        "           prop_delta_neg, prop_delta_zero, prop_delta_pos]\n",
        "    dpo_summary.loc[len(dpo_summary.index)] = row\n",
        "\n",
        "# save to our cleaned directory\n",
        "dpo_summary.to_csv(\"cleaned_results/dpo_summary.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b368e83e",
      "metadata": {
        "id": "b368e83e"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Metrics of Interest:\n",
        "1. final test acc, Delta (batch-acc-pre, post) (<0, =0, >0)\n",
        "2. mu_is (i=0, to i=6) - i.e., posterior reward means per arm\n",
        "'''\n",
        "# create summary logs for Thompson Sampling\n",
        "tsw_summary = pd.DataFrame(\n",
        "    data=None, columns=[\n",
        "        \"method\", \"dataset\", \"piv\", \"seed\", \"final_test_acc\",\n",
        "        \"prop_delta_neg\", \"prop_delta_zero\", \"prop_delta_pos\"]\\\n",
        "    + [f\"mu_{i}\" for i in range(7)])\n",
        "\n",
        "# fill out these logs for Thomspon Sampling\n",
        "tsw_fnames = sorted([f for f in os.listdir(\"raw_results/skyler\") if \"TSW\" in f])\n",
        "for fname in tsw_fnames:\n",
        "\n",
        "    # record our settings\n",
        "    method = \"TSW\"\n",
        "    dataset = fname.split(\"_\")[1].split(\"=\")[1]\n",
        "    piv = float(fname.split(\"_\")[2].split(\"=\")[1])\n",
        "    seed = int(fname.split(\"_\")[3].split(\"=\")[1].split(\".csv\")[0])\n",
        "\n",
        "    # load in our dataframe\n",
        "    df = pd.read_csv(f\"raw_results/skyler/{fname}\")\n",
        "    final_test_acc = df.test_acc.values[-1]\n",
        "\n",
        "    # compute our delta statistics\n",
        "    deltas = (df.batch_acc_post - df.batch_acc_pre)\n",
        "    prop_delta_neg = (deltas < 0).mean()\n",
        "    prop_delta_zero = (deltas == 0).mean()\n",
        "    prop_delta_pos = (deltas > 0).mean()\n",
        "\n",
        "    # get our Beta hyperparameters\n",
        "    a = df[[f\"a{i}\" for i in range(7)]].values\n",
        "    b = df[[f\"b{i}\" for i in range(7)]].values\n",
        "    mus = (a / (a+b))[-1,:]\n",
        "\n",
        "    # assemble row + add to our dataframe\n",
        "    row = [method, dataset, piv, seed, final_test_acc,\n",
        "           prop_delta_neg, prop_delta_zero, prop_delta_pos] + list(mus)\n",
        "    tsw_summary.loc[len(tsw_summary.index)] = row\n",
        "\n",
        "# save to our cleaned directory\n",
        "tsw_summary.to_csv(\"cleaned_results/tsw_summary.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2194e1eb",
      "metadata": {
        "id": "2194e1eb"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Offline Variants:\n",
        "VDW - MRPO/MDPO: 2x (\"Offline 1\")\n",
        "VAW - MRPO/MDPO: 2x (\"Offline 2\")\n",
        "'''\n",
        "# create summary logs for Offline 1 + Offline 2\n",
        "offlines_summary = pd.DataFrame(\n",
        "    data=None, columns=[\n",
        "        \"method\", \"dataset\", \"base\", \"seed\", \"final_test_acc\",\n",
        "        \"prop_delta_neg\", \"prop_delta_zero\", \"prop_delta_pos\"]\\\n",
        "    + [f\"alpha_{i}\" for i in range(7)])\n",
        "\n",
        "# fill out these logs for Offline Methods\n",
        "offlines_fnames = sorted([f for f in os.listdir(\"raw_results/aymen\") if \"VAW\" in f or \"VDW\" in f])\n",
        "for fname in offlines_fnames:\n",
        "\n",
        "    # extract out our settings\n",
        "    dataset, method, seed, base = fname.replace(\".csv\", \"\").split(\"_\"); seed = int(seed)\n",
        "\n",
        "    # load in our dataframe\n",
        "    df = pd.read_csv(f\"raw_results/aymen/{fname}\")\n",
        "    final_test_acc = float(df.test_acc.values[-1].split(\", device\")[0].split(\"tensor(\")[1])\n",
        "\n",
        "    # compute our delta statistics\n",
        "    deltas = (df.batch_acc_post - df.batch_acc_pre)\n",
        "    prop_delta_neg = (deltas < 0).mean()\n",
        "    prop_delta_zero = (deltas == 0).mean()\n",
        "    prop_delta_pos = (deltas > 0).mean()\n",
        "\n",
        "    # also extract our alphas\n",
        "    alphas = df[[col for col in df.columns if \"alpha\" in col]].values[-1]\n",
        "\n",
        "    # assemble row + add to our dataframe\n",
        "    row = [method, dataset, base, seed, final_test_acc,\n",
        "           prop_delta_neg, prop_delta_zero, prop_delta_pos] + list(alphas)\n",
        "    offlines_summary.loc[len(offlines_summary.index)] = row\n",
        "\n",
        "# save to our cleaned directory\n",
        "offlines_summary.to_csv(\"cleaned_results/offlines_summary.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0527f20",
      "metadata": {
        "id": "d0527f20"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Online 1 Variants:\n",
        "SWCW - MRPO/MDPO: 2x (\"Online 1\")\n",
        "SWCW-OH - MRPO/MDPO: 2x (\"Online 1 (0-1)\")\n",
        "'''\n",
        "# create summary logs for the Online 1 variants.\n",
        "swcw_summary = pd.DataFrame(\n",
        "    data=None, columns=[\n",
        "        \"method\", \"dataset\", \"base\", \"seed\", \"one_hot\", \"final_test_acc\",\n",
        "        \"prop_delta_neg\", \"prop_delta_zero\", \"prop_delta_pos\"])\n",
        "\n",
        "# fill out these logs for Aymen's original SWCW runs first.\n",
        "swcw_fnames = sorted([f for f in os.listdir(\"raw_results/aymen\") if \"SWCW\" in f])\n",
        "for fname in swcw_fnames:\n",
        "\n",
        "    # extract out our settings\n",
        "    dataset, method, seed, base = fname.replace(\".csv\", \"\").split(\"_\"); seed = int(seed)\n",
        "\n",
        "    # load in our dataframe\n",
        "    df = pd.read_csv(f\"raw_results/aymen/{fname}\")\n",
        "    final_test_acc = float(df.test_acc.values[-1].split(\", device\")[0].split(\"tensor(\")[1])\n",
        "\n",
        "    # compute our delta statistics\n",
        "    deltas = (df.batch_acc_post - df.batch_acc_pre)\n",
        "    prop_delta_neg = (deltas < 0).mean()\n",
        "    prop_delta_zero = (deltas == 0).mean()\n",
        "    prop_delta_pos = (deltas > 0).mean()\n",
        "\n",
        "    # assemble row + add to our dataframe\n",
        "    row = [method, dataset, base, seed, False, final_test_acc,\n",
        "           prop_delta_neg, prop_delta_zero, prop_delta_pos]\n",
        "    swcw_summary.loc[len(swcw_summary.index)] = row\n",
        "\n",
        "# now work on Skyler's SWCW-OH runs next.\n",
        "swcw_fnames = sorted([f for f in os.listdir(\"raw_results/skyler\") if \"SWCW\" in f])\n",
        "for fname in swcw_fnames:\n",
        "\n",
        "    # extract out our settings\n",
        "    dataset = fname.split(\"_\")[1].split(\"=\")[1]\n",
        "    method = \"SWCW\"\n",
        "    seed = int(fname.split(\"_\")[2].replace(\".csv\", \"\").split(\"=\")[1])\n",
        "    base = \"MRPO\"\n",
        "\n",
        "    # load in our dataframe\n",
        "    df = pd.read_csv(f\"raw_results/skyler/{fname}\")\n",
        "    final_test_acc = df.test_acc.values[-1]\n",
        "\n",
        "    # compute our delta statistics\n",
        "    deltas = (df.batch_acc_post - df.batch_acc_pre)\n",
        "    prop_delta_neg = (deltas < 0).mean()\n",
        "    prop_delta_zero = (deltas == 0).mean()\n",
        "    prop_delta_pos = (deltas > 0).mean()\n",
        "\n",
        "    # assemble row + add to our dataframe\n",
        "    row = [method, dataset, base, seed, True, final_test_acc,\n",
        "           prop_delta_neg, prop_delta_zero, prop_delta_pos]\n",
        "    swcw_summary.loc[len(swcw_summary.index)] = row\n",
        "\n",
        "# save to our cleaned directory\n",
        "swcw_summary.to_csv(\"cleaned_results/online-1s_summary.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e53aa6d",
      "metadata": {
        "id": "3e53aa6d"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Original - MRPO/MDPO: 2x.\n",
        "'''\n",
        "# create summary logs for Offline 1 + Offline 2\n",
        "originals_summary = pd.DataFrame(\n",
        "    data=None, columns=[\n",
        "        \"method\", \"dataset\", \"base\", \"seed\", \"final_test_acc\",\n",
        "        \"prop_delta_neg\", \"prop_delta_zero\", \"prop_delta_pos\"])\n",
        "\n",
        "# fill out these logs for Le et al.'s original method.\n",
        "originals_fnames = sorted([f for f in os.listdir(\"raw_results/aymen\") if \"Original\" in f])\n",
        "for fname in originals_fnames:\n",
        "\n",
        "    # extract out our settings\n",
        "    dataset, method, seed, base = fname.replace(\".csv\", \"\").split(\"_\"); seed = int(seed)\n",
        "\n",
        "    # load in our dataframe\n",
        "    df = pd.read_csv(f\"raw_results/aymen/{fname}\")\n",
        "    final_test_acc = float(df.test_acc.values[-1].split(\", device\")[0].split(\"tensor(\")[1])\n",
        "\n",
        "    # compute our delta statistics\n",
        "    deltas = (df.batch_acc_post - df.batch_acc_pre)\n",
        "    prop_delta_neg = (deltas < 0).mean()\n",
        "    prop_delta_zero = (deltas == 0).mean()\n",
        "    prop_delta_pos = (deltas > 0).mean()\n",
        "\n",
        "    # assemble row + add to our dataframe\n",
        "    row = [method, dataset, base, seed, final_test_acc,\n",
        "           prop_delta_neg, prop_delta_zero, prop_delta_pos]\n",
        "    originals_summary.loc[len(originals_summary.index)] = row\n",
        "\n",
        "# save to our cleaned directory\n",
        "originals_summary.to_csv(\"cleaned_results/originals_summary.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 (Afterburner)",
      "language": "python",
      "name": "afterburner"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}