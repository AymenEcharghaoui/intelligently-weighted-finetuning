{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32552de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\n",
    "import os\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "# Mount Google Drive to get access to data and save logs/models\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "\n",
    "MODEL_DIR = \"/content/drive/MyDrive/mypartcs329h/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if models dir is not there, create it and download models\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "MODELSLIST = [\n",
    "    \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "    \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    \"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "    \"01-ai/Yi-1.5-9B-Chat\",\n",
    "    \"microsoft/Phi-3-medium-128k-instruct\"\n",
    "]\n",
    "# downloading models\n",
    "for model_name in MODELSLIST :\n",
    "    # laoding model and tokenizer\n",
    "    ref_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map='auto'\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    save_dir = MODEL_DIR + f\"{model_name.replace('/', '_')}\"\n",
    "    # saving model and tokenizer\n",
    "    ref_model.save_pretrained(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)\n",
    "    # cleaning up to free memory\n",
    "    del ref_model\n",
    "    del tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
